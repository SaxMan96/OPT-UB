{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Optimization Laboratory 4: Constrained optimization: equality constraints </h1> </center> \n",
    "\n",
    "<center> <h3> Alfons Cordoba / Mateusz Dorobek / Emilio Tylson Baixauli </h3> </center> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments of Sequetinal Quadratic Programing\n",
    "\n",
    "### 1 - Newton step with fixed starting point\n",
    "\n",
    "The first experiment consist in appling the Sequential Quadratic Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x):\n",
    "    return np.array( [3 * np.exp(3 * x[0]) - 2 * x[2] * x[0], -4 * np.exp(-4 * x[1]) - 2 * x[2] * x[1], \n",
    "                      - x[0] ** 2 - x[1] ** 2 + 1])\n",
    "\n",
    "def hessian(x):\n",
    "    row_0 = np.array([9 * np.exp(3 * x[0]) - 2 * x[2], 0, -2 * x[0]]).reshape(3, 1)\n",
    "    row_1 = np.array([0, 16 * np.exp(-4 * x[1]) - 2 * x[2], -2 * x[1]]).reshape(3, 1)\n",
    "    row_2 = np.array([-2 * x[0], -2 * x[1], 0]).reshape(3, 1)\n",
    "    return np.concatenate((row_0, row_1, row_2), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def rh_gen(F):\n",
    "    def rh_update(z, n):\n",
    "        return -F(z)\n",
    "\n",
    "    return rh_update\n",
    "\n",
    "def hess_lag_gen(H):\n",
    "    \n",
    "    def hess_lag_update(z, n):\n",
    "        return H(z)\n",
    "    \n",
    "    return hess_lag_update\n",
    "\n",
    "\n",
    "def step(z, rh, hess_lag, rh_update, hess_lag_update, n, alpha=1, epsilon=1e-10):\n",
    "    dz = np.linalg.solve(hess_lag, rh)\n",
    "    z = z + alpha * dz\n",
    "    rh = rh_update(z, n)\n",
    "    hess_lag = hess_lag_update(z, n)\n",
    "    eps_condition = np.linalg.norm(rh[:2]) > epsilon\n",
    "    return eps_condition, z, rh, hess_lag\n",
    "\n",
    "\n",
    "def loop(z, n=None):\n",
    "    eps_condition = True\n",
    "    niter = 1000\n",
    "    i_loop = 0\n",
    "    rh_update = rh_gen(grad)\n",
    "    hess_lag_update = hess_lag_gen(hessian)\n",
    "    rh = rh_update(z, n)\n",
    "    hess_lag = hess_lag_update(z, n)\n",
    "    while eps_condition and i_loop < niter:\n",
    "        eps_condition, z, rh, hess_lag = step(z, rh, hess_lag, rh_update, hess_lag_update, n)\n",
    "        i_loop += 1\n",
    "    return z\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797494772209388e-06\n"
     ]
    }
   ],
   "source": [
    "z0 = np.array([-1, 1, -1])\n",
    "original = np.array([-0.74834, 0.66332, -0.21233])\n",
    "print(\"The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\")\n",
    "res = loop(z0)\n",
    "print(\"The algorithm obtained \", res)\n",
    "error = np.linalg.norm(original - res)\n",
    "print(\"Error\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The obtained solution is approximatly the same as the therical solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Newton step with random starting point\n",
    "\n",
    "The second experiment anlyses different starting points, and the convergence to the theorical solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******\n",
      "Starting point  [0.29288102 1.2911362 ]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486603500676e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 0.2692991 -0.4580712]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [ 0.91041323 -0.41370006 25.2938552 ]\n",
      "Error 25.58274649409391\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-0.37447673  2.350638  ]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797501908791518e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-0.69935089  1.75035023]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486603574388e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [0.40826737 2.55357983]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486659988018e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-2.4772242  -2.87868962]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [nan nan nan]\n",
      "Error nan\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [1.66894051 2.22007289]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.7974866035491335e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 1.79495139 -0.23112383]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486603521355e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-2.29035344  0.83952613]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797489801831421e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [2.6680135  0.13108993]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.7974891702964175e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-1.41266633  1.64540214]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486603555614e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 0.41060369 -2.8872612 ]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [ 1.43452315e-02 -9.99897102e-01  1.09162598e+02]\n",
      "Error 109.39023155227295\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [0.67257434 0.70160398]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486603479996e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 1.09092179 -0.8429526 ]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [ 0.91041323 -0.41370006 25.2938552 ]\n",
      "Error 25.582746494093914\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 1.18578718 -2.63864717]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [ 0.91041323 -0.41370006 25.2938552 ]\n",
      "Error 25.582746494093914\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 1.02382722 -1.73770463]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [ 1.43452315e-02 -9.99897102e-01  1.09162598e+02]\n",
      "Error 109.39023155228504\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-1.10742989 -0.81773537]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486603470748e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-0.36839092  2.93024303]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797487634379642e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-1.74673946 -2.03214289]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [ 0.91041323 -0.41370006 25.2938552 ]\n",
      "Error 25.582746494093914\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-1.48025038 -0.20213536]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486603521355e-06\n",
      "*******\n",
      "\n",
      "Max error  109.39023155228504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emiliotylson/.local/share/virtualenvs/Optimization-n0N5CbKl/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/Users/emiliotylson/.local/share/virtualenvs/Optimization-n0N5CbKl/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "test_starting_points = np.random.uniform(-3, 3, (20, 3))\n",
    "max_err = 0\n",
    "for test_starting_point in test_starting_points:\n",
    "    print(\"*******\")\n",
    "    print(\"Starting point \",test_starting_point[:2])\n",
    "    res = loop(test_starting_point)\n",
    "    print(\"The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\")\n",
    "    print(\"The algorithm obtained \", res)\n",
    "    error = np.linalg.norm(original - res)\n",
    "    print(\"Error\", error)\n",
    "    print(\"*******\")\n",
    "    print()\n",
    "    max_err = error if error > max_err else max_err\n",
    "print(\"Max error \", max_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By evaluating 20 random starting points, we concluded the algorithm is highly sensitive to them. We have obtained errors of 109.39. \n",
    "As the algortih is stating on points close to the solution, the Lagrangian not be convex in those points. Thus, the algorithm diverges form the solution. Therefore, it is important to apply a startegy that can approximate the starting point for a correct convergence to the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Merit function\n",
    "\n",
    "In this experiment we apply the merit that helps to find an approximate close point to the solution so the Sequetinal Quadratic can be applyed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.exp(3 * x[0]) + np.exp(-4 * x[1])\n",
    "\n",
    "def grad_f(x):\n",
    "    return np.array([3*np.exp(3 * x[0]), -4 * np.exp(-4 * x[1])])\n",
    "    \n",
    "def h(x):\n",
    "    return x[0]**2 + x[1]**2 - 1\n",
    "\n",
    "def grad_h(x):\n",
    "    return np.array([2*x[0], 2*x[1]])\n",
    "\n",
    "def merit_function(x, p=10):\n",
    "    return  f(x)+ p *(h(x))**2\n",
    "\n",
    "def grad_merit_function(x, p=10):\n",
    "    return grad_f(x) + p * 2 * h(x) * grad_h(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRADIENT DESCENT WITH ADAPTATIVE ALPHA AND FIXED STEP\n",
    "def grad_descent(f,grad_f,x0,fdif_threshold = 1e-20,grad_threshold = 1e-20,alfa_threshold = 1e-20):\n",
    "\n",
    "    x1 = x0\n",
    "    f1 = f(x1)\n",
    "    \n",
    "    x_list= []\n",
    "    x_list.append(x1)\n",
    "    gradf_list = []\n",
    "    \n",
    "    loop_out = True\n",
    "    loop_alfa = True\n",
    "    j=0\n",
    "    print ('x0:',x1,'f1:',f1,end = ' ')\n",
    "    while loop_out:\n",
    "        j=j+1\n",
    "        gradf = grad_f(x1)\n",
    "        gradf_list.append(gradf)\n",
    "        if np.linalg.norm(gradf) <= grad_threshold:\n",
    "            print('grad_threshold:', np.linalg.norm(gradf),'x2:',x2,'loops:',j)\n",
    "            return x2, np.array(x_list), np.array(gradf_list)\n",
    "        \n",
    "        alfa = 1.0\n",
    "        i=0\n",
    "        while loop_alfa:\n",
    "            i=i+1\n",
    "            if alfa < alfa_threshold:\n",
    "                x_list.append(x2)\n",
    "                print('alfa_threshold:',alfa,'x2:',x2,'inner loops:',i,'outer loops:',j)\n",
    "                return x2, np.array(x_list), np.array(gradf_list)\n",
    "            else:\n",
    "                x2 = x1 - alfa*gradf\n",
    "                f2 = f(x2)\n",
    "                if f2 < f1:\n",
    "                    loop_alfa = False\n",
    "                else:\n",
    "                    alfa = alfa/2\n",
    "        loop_alfa = True  \n",
    "        x_list.append(x2)\n",
    "        if abs(f2-f1) <= fdif_threshold:\n",
    "            print('fdif_threshold:',abs(f2-f1),'x2:',x2,'loops:',j)\n",
    "            return x2, np.array(x_list), np.array(gradf_list)\n",
    "\n",
    "        x1 = x2\n",
    "        f1 = f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0: [3, 2] f1: 9543.084263038012 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242933  0.6665431 ] inner loops: 68 outer loops: 367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emiliotylson/.local/share/virtualenvs/Optimization-n0N5CbKl/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.75242933,  0.6665431 ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merit function approximation\n",
    "x0 = [3,2]\n",
    "x, x_list,_ = grad_descent(merit_function,grad_merit_function,x0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******\n",
      "Starting point  [0.29288102 1.2911362 ]\n",
      "x0: [0.29288102 1.2911362 ] f1: 8.08060488598412 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 353\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242932  0.66654311]\n",
      "Error 0.005206822864816334\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 0.2692991 -0.4580712]\n",
      "x0: [ 0.2692991 -0.4580712] f1: 13.641530029602688 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242936  0.66654307] inner loops: 68 outer loops: 354\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242936  0.66654307]\n",
      "Error 0.005206826134534426\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-0.37447673  2.350638  ]\n",
      "x0: [-0.37447673  2.350638  ] f1: 218.0157821904091 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242931  0.66654312] inner loops: 68 outer loops: 345\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242931  0.66654312]\n",
      "Error 0.005206822727415714\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-0.69935089  1.75035023]\n",
      "x0: [-0.69935089  1.75035023] f1: 65.29238198398882 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 364\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242932  0.66654311]\n",
      "Error 0.005206822061664267\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [0.40826737 2.55357983]\n",
      "x0: [0.40826737 2.55357983] f1: 326.8746531885091 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242935  0.66654308] inner loops: 68 outer loops: 354\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242935  0.66654308]\n",
      "Error 0.005206825086362246\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-2.4772242  -2.87868962]\n",
      "x0: [-2.4772242  -2.87868962] f1: 101985.37015193114 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emiliotylson/.local/share/virtualenvs/Optimization-n0N5CbKl/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alfa_threshold: 6.776263578034403e-21 x2: [-0.75242935  0.66654308] inner loops: 68 outer loops: 334\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242935  0.66654308]\n",
      "Error 0.005206824843739598\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [1.66894051 2.22007289]\n",
      "x0: [1.66894051 2.22007289] f1: 600.218676389356 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242935  0.66654308] inner loops: 68 outer loops: 363\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242935  0.66654308]\n",
      "Error 0.005206824354922578\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 1.79495139 -0.23112383]\n",
      "x0: [ 1.79495139 -0.23112383] f1: 272.3673686804759 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 375\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242932  0.66654311]\n",
      "Error 0.005206822906889159\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-2.29035344  0.83952613]\n",
      "x0: [-2.29035344  0.83952613] f1: 245.11262041021288 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242935  0.66654308] inner loops: 68 outer loops: 365\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242935  0.66654308]\n",
      "Error 0.005206825415369594\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [2.6680135  0.13108993]\n",
      "x0: [2.6680135  0.13108993] f1: 3370.060092670731 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 348\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242932  0.66654311]\n",
      "Error 0.005206822085400645\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-1.41266633  1.64540214]\n",
      "x0: [-1.41266633  1.64540214] f1: 137.13601196553827 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 373\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242932  0.66654311]\n",
      "Error 0.005206823164293516\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 0.41060369 -2.8872612 ]\n",
      "x0: [ 0.41060369 -2.8872612 ] f1: 104244.61379803663 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 354\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242932  0.66654311]\n",
      "Error 0.005206822404796249\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [0.67257434 0.70160398]\n",
      "x0: [0.67257434 0.70160398] f1: 7.612287663792581 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 345\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242932  0.66654311]\n",
      "Error 0.005206821684613692\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 1.09092179 -0.8429526 ]\n",
      "x0: [ 1.09092179 -0.8429526 ] f1: 63.62765367200652 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654312] inner loops: 68 outer loops: 336\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242932  0.66654312]\n",
      "Error 0.005206821370488255\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 1.18578718 -2.63864717]\n",
      "x0: [ 1.18578718 -2.63864717] f1: 38931.05079130816 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242931  0.66654312] inner loops: 68 outer loops: 370\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242931  0.66654312]\n",
      "Error 0.005206822263557584\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 1.02382722 -1.73770463]\n",
      "x0: [ 1.02382722 -1.73770463] f1: 1159.6941714252484 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242936  0.66654307] inner loops: 68 outer loops: 273\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242936  0.66654307]\n",
      "Error 0.0052068263535744105\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-1.10742989 -0.81773537]\n",
      "x0: [-1.10742989 -0.81773537] f1: 34.38409213127558 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242933  0.6665431 ] inner loops: 68 outer loops: 373\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242933  0.6665431 ]\n",
      "Error 0.005206823635356249\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-0.36839092  2.93024303]\n",
      "x0: [-0.36839092  2.93024303] f1: 596.6295731628727 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242935  0.66654308] inner loops: 68 outer loops: 356\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242935  0.66654308]\n",
      "Error 0.0052068243923697926\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-1.74673946 -2.03214289]\n",
      "x0: [-1.74673946 -2.03214289] f1: 3771.9700512624854 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242935  0.66654307] inner loops: 68 outer loops: 358\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242935  0.66654307]\n",
      "Error 0.005206824771825099\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-1.48025038 -0.20213536]\n",
      "x0: [-1.48025038 -0.20213536] f1: 17.434656471206537 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242936  0.66654307] inner loops: 68 outer loops: 315\n",
      "The original solution is x = (−0.74834, 0.66332) \n",
      "The merit function optimization algorithm obtained  [-0.75242936  0.66654307]\n",
      "Error 0.005206826968786757\n",
      "*******\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "test_starting_points = np.random.uniform(-3, 3, (20, 3))\n",
    "max_err = 0\n",
    "acum_error = []\n",
    "for test_starting_point in test_starting_points:\n",
    "    print(\"*******\")\n",
    "    print(\"Starting point \",test_starting_point[:2])\n",
    "    res, x_list,_ = grad_descent(merit_function,grad_merit_function, test_starting_point[:2])\n",
    "    print(\"The original solution is x = (−0.74834, 0.66332) \")\n",
    "    print(\"The merit function optimization algorithm obtained \", res)\n",
    "    error = np.linalg.norm(original[:2] - res)\n",
    "    print(\"Error\", error)\n",
    "    print(\"*******\")\n",
    "    print()\n",
    "    max_err = acum_error.append(error) \n",
    "    \n",
    "acum_error = np.array(acum_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error  0.005206826968786757\n",
      "Mean error  0.005206823774538808\n"
     ]
    }
   ],
   "source": [
    "print(\"Max error \", acum_error.max())\n",
    "print(\"Mean error \", acum_error.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After starting with 20 random points, we can obtained a mean error of 0.0052. Therefore we conclude from the experment that the merit function can approximate the point to one near to the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Finding better starting point\n",
    "\n",
    "As the merit funtion finds a close point to the solution, we proceed on combining the merit function to find a starting point for the sequential quadratic method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******\n",
      "Starting point  [0.29288102 1.2911362 ]\n",
      "x0: [0.29288102 1.2911362 ] f1: 8.08060488598412 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 353\n",
      "Merit starting point  [-0.75242932  0.66654311  0.61658026]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486603595066e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 0.2692991 -0.4580712]\n",
      "x0: [ 0.2692991 -0.4580712] f1: 13.641530029602688 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242936  0.66654307] inner loops: 68 outer loops: 354\n",
      "Merit starting point  [-0.75242936  0.66654307  0.87536468]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797493912058464e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-0.37447673  2.350638  ]\n",
      "x0: [-0.37447673  2.350638  ] f1: 218.0157821904091 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242931  0.66654312] inner loops: 68 outer loops: 345\n",
      "Merit starting point  [-0.75242931  0.66654312  2.78197656]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.7974866036228465e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-0.69935089  1.75035023]\n",
      "x0: [-0.69935089  1.75035023] f1: 65.29238198398882 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 364\n",
      "Merit starting point  [-0.75242932  0.66654311  0.17336952]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797487032131134e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [0.40826737 2.55357983]\n",
      "x0: [0.40826737 2.55357983] f1: 326.8746531885091 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242935  0.66654308] inner loops: 68 outer loops: 354\n",
      "Merit starting point  [-0.75242935  0.66654308 -2.57378365]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797490634155192e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-2.4772242  -2.87868962]\n",
      "x0: [-2.4772242  -2.87868962] f1: 101985.37015193114 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242935  0.66654308] inner loops: 68 outer loops: 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emiliotylson/.local/share/virtualenvs/Optimization-n0N5CbKl/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merit starting point  [-0.75242935  0.66654308  1.99571907]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797499019277177e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [1.66894051 2.22007289]\n",
      "x0: [1.66894051 2.22007289] f1: 600.218676389356 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242935  0.66654308] inner loops: 68 outer loops: 363\n",
      "Merit starting point  [-0.75242935  0.66654308  2.87171005]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486603553708e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 1.79495139 -0.23112383]\n",
      "x0: [ 1.79495139 -0.23112383] f1: 272.3673686804759 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 375\n",
      "Merit starting point  [-0.75242932  0.66654311  1.68317506]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797497024025668e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-2.29035344  0.83952613]\n",
      "x0: [-2.29035344  0.83952613] f1: 245.11262041021288 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242935  0.66654308] inner loops: 68 outer loops: 365\n",
      "Merit starting point  [-0.75242935  0.66654308 -2.13988028]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797489050454731e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [2.6680135  0.13108993]\n",
      "x0: [2.6680135  0.13108993] f1: 3370.060092670731 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 348\n",
      "Merit starting point  [-0.75242932  0.66654311 -0.51202836]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486612710655e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-1.41266633  1.64540214]\n",
      "x0: [-1.41266633  1.64540214] f1: 137.13601196553827 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 373\n",
      "Merit starting point  [-0.75242932  0.66654311 -0.26309801]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486603562714e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 0.41060369 -2.8872612 ]\n",
      "x0: [ 0.41060369 -2.8872612 ] f1: 104244.61379803663 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 354\n",
      "Merit starting point  [-0.75242932  0.66654311  0.70581298]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486603574388e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [0.67257434 0.70160398]\n",
      "x0: [0.67257434 0.70160398] f1: 7.612287663792581 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654311] inner loops: 68 outer loops: 345\n",
      "Merit starting point  [-0.75242932  0.66654311  2.66248847]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.7974866036228465e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 1.09092179 -0.8429526 ]\n",
      "x0: [ 1.09092179 -0.8429526 ] f1: 63.62765367200652 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242932  0.66654312] inner loops: 68 outer loops: 336\n",
      "Merit starting point  [-0.75242932  0.66654312 -0.37780828]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486604549677e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 1.18578718 -2.63864717]\n",
      "x0: [ 1.18578718 -2.63864717] f1: 38931.05079130816 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242931  0.66654312] inner loops: 68 outer loops: 370\n",
      "Merit starting point  [-0.75242931  0.66654312  1.00060029]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797494237783046e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [ 1.02382722 -1.73770463]\n",
      "x0: [ 1.02382722 -1.73770463] f1: 1159.6941714252484 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242936  0.66654307] inner loops: 68 outer loops: 273\n",
      "Merit starting point  [-0.75242936  0.66654307 -2.22644221]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797489333832134e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-1.10742989 -0.81773537]\n",
      "x0: [-1.10742989 -0.81773537] f1: 34.38409213127558 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242933  0.6665431 ] inner loops: 68 outer loops: 373\n",
      "Merit starting point  [-0.75242933  0.6665431   0.42118062]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797486603553708e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-0.36839092  2.93024303]\n",
      "x0: [-0.36839092  2.93024303] f1: 596.6295731628727 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242935  0.66654308] inner loops: 68 outer loops: 356\n",
      "Merit starting point  [-0.75242935  0.66654308 -2.38773114]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797489904615113e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-1.74673946 -2.03214289]\n",
      "x0: [-1.74673946 -2.03214289] f1: 3771.9700512624854 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242935  0.66654307] inner loops: 68 outer loops: 358\n",
      "Merit starting point  [-0.75242935  0.66654307  0.91864995]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797494049305949e-06\n",
      "*******\n",
      "\n",
      "*******\n",
      "Starting point  [-1.48025038 -0.20213536]\n",
      "x0: [-1.48025038 -0.20213536] f1: 17.434656471206537 alfa_threshold: 6.776263578034403e-21 x2: [-0.75242936  0.66654307] inner loops: 68 outer loops: 315\n",
      "Merit starting point  [-0.75242936  0.66654307 -1.53344645]\n",
      "The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\n",
      "The algorithm obtained  [-0.74833549  0.66332043 -0.21232494]\n",
      "Error 6.797487524165623e-06\n",
      "*******\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "test_starting_points = np.random.uniform(-3, 3, (20, 3))\n",
    "acum_error = []\n",
    "for test_starting_point in test_starting_points:\n",
    "    print(\"*******\")\n",
    "    print(\"Starting point \",test_starting_point[:2])\n",
    "    test_starting_point[:2], x_list,_ = grad_descent(merit_function,grad_merit_function, test_starting_point[:2])\n",
    "    print(\"Merit starting point \", test_starting_point)\n",
    "    res = loop(test_starting_point)\n",
    "    print(\"The theorical solution is x = (−0.74834, 0.66332) and lambda = (−0.21233)\")\n",
    "    print(\"The algorithm obtained \", res)\n",
    "    error = np.linalg.norm(original - res)\n",
    "    print(\"Error\", error)\n",
    "    print(\"*******\")\n",
    "    print()\n",
    "    acum_error.append(error)\n",
    "acum_error = np.array([acum_error])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error  6.797489558207493e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean error \", acum_error.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After starting the full algoith with different starting points we see the combination of the two algorithms mangaed to find the solution. Comparing to previous result, this method obtained the best convergence of all. The merit function optimization method alone obtained a point with an error around 0.0052, while the combination with the sequential quadratic method obtained an error of 6.8 e-6. This is a critical improvement of the convergence to the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The sequential quadratic method is an interative method that allows the optimization of constrained functions by using second order information of the Lagrangian function. Despite converging to the solution, this convergence strongly depends on the starting point. This starting point should be near the solution so the method takes advantage on the convexity of the function. In order to find better starting points, the laboratory proposes the merit function optimization. This function penalises points outside the feasible set. By minimizaing this function, it can be obtained an approximation that is close to the solution but could be outside the feasible set. Then, by using this point as a starting point of the afformentioned sequential quadratic method, we can build a method for optimizing contrained function that not depends on the starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
